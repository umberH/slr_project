{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score\n",
    "# import interpretability_module as interp\n",
    "# from utils import *\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, confusion_matrix, f1_score, average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_data = pd.read_csv('../../../data/churn_examples/telecom_customer_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Gender', 'Age', 'Married', 'Number of Dependents',\n",
       "       'City', 'Zip Code', 'Latitude', 'Longitude', 'Number of Referrals',\n",
       "       'Tenure in Months', 'Offer', 'Phone Service',\n",
       "       'Avg Monthly Long Distance Charges', 'Multiple Lines',\n",
       "       'Internet Service', 'Internet Type', 'Avg Monthly GB Download',\n",
       "       'Online Security', 'Online Backup', 'Device Protection Plan',\n",
       "       'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
       "       'Streaming Music', 'Unlimited Data', 'Contract', 'Paperless Billing',\n",
       "       'Payment Method', 'Monthly Charge', 'Total Charges', 'Total Refunds',\n",
       "       'Total Extra Data Charges', 'Total Long Distance Charges',\n",
       "       'Total Revenue', 'Customer Status', 'Churn Category', 'Churn Reason'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Customer ID                        7043 non-null   object \n",
      " 1   Gender                             7043 non-null   object \n",
      " 2   Age                                7043 non-null   int64  \n",
      " 3   Married                            7043 non-null   object \n",
      " 4   Number of Dependents               7043 non-null   int64  \n",
      " 5   City                               7043 non-null   object \n",
      " 6   Zip Code                           7043 non-null   int64  \n",
      " 7   Latitude                           7043 non-null   float64\n",
      " 8   Longitude                          7043 non-null   float64\n",
      " 9   Number of Referrals                7043 non-null   int64  \n",
      " 10  Tenure in Months                   7043 non-null   int64  \n",
      " 11  Offer                              7043 non-null   object \n",
      " 12  Phone Service                      7043 non-null   object \n",
      " 13  Avg Monthly Long Distance Charges  6361 non-null   float64\n",
      " 14  Multiple Lines                     6361 non-null   object \n",
      " 15  Internet Service                   7043 non-null   object \n",
      " 16  Internet Type                      5517 non-null   object \n",
      " 17  Avg Monthly GB Download            5517 non-null   float64\n",
      " 18  Online Security                    5517 non-null   object \n",
      " 19  Online Backup                      5517 non-null   object \n",
      " 20  Device Protection Plan             5517 non-null   object \n",
      " 21  Premium Tech Support               5517 non-null   object \n",
      " 22  Streaming TV                       5517 non-null   object \n",
      " 23  Streaming Movies                   5517 non-null   object \n",
      " 24  Streaming Music                    5517 non-null   object \n",
      " 25  Unlimited Data                     5517 non-null   object \n",
      " 26  Contract                           7043 non-null   object \n",
      " 27  Paperless Billing                  7043 non-null   object \n",
      " 28  Payment Method                     7043 non-null   object \n",
      " 29  Monthly Charge                     7043 non-null   float64\n",
      " 30  Total Charges                      7043 non-null   float64\n",
      " 31  Total Refunds                      7043 non-null   float64\n",
      " 32  Total Extra Data Charges           7043 non-null   int64  \n",
      " 33  Total Long Distance Charges        7043 non-null   float64\n",
      " 34  Total Revenue                      7043 non-null   float64\n",
      " 35  Customer Status                    7043 non-null   object \n",
      " 36  Churn Category                     1869 non-null   object \n",
      " 37  Churn Reason                       1869 non-null   object \n",
      "dtypes: float64(9), int64(6), object(23)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "telecom_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stayed     4720\n",
       "Churned    1869\n",
       "Joined      454\n",
       "Name: Customer Status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_data['Customer Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_data['Gender'].replace(['Female', 'Male'],[0, 1], inplace=True)\n",
    "telecom_data['Married'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Online Security'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Online Backup'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Internet Service'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Phone Service'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Multiple Lines'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Device Protection Plan'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Premium Tech Support'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Offer'].replace(['None', '0','1','2','3','4'],[-1,0, 1,2,3,4], inplace=True)\n",
    "telecom_data['Payment Method'].replace(['Bank Withdrawal', 'Credit Card','Mailed Check'],[0, 1,2], inplace=True)\n",
    "\n",
    "telecom_data['Streaming TV'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Streaming Movies'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Streaming Music'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Paperless Billing'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "telecom_data['Unlimited Data'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "\n",
    "telecom_data['Contract'].replace(['Month-to-Month', 'Two Year','One Year'],[1, 2,3], inplace=True)\n",
    "\n",
    "telecom_data['Offer'].replace(['Offer A', 'Offer B','Offer C','Offer D','Offer E'],[0, 1,2,3,4], inplace=True)\n",
    "telecom_data['Internet Type'].replace(['Fiber Optic','DSL','Cable'],[1,2,3], inplace=True)\n",
    "telecom_data['Customer Status'].replace(['Stayed','Joined','Churned'],[1,2,3], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Follows algo from https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf\n",
    "\n",
    "def c(size):\n",
    "    if size > 2:\n",
    "        return 2 * (np.log(size-1)+0.5772156649) - 2*(size-1)/size\n",
    "    if size == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, size, data):\n",
    "        self.size = size\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, left, right, splitAtt, splitVal):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.splitAtt = splitAtt\n",
    "        self.splitVal = splitVal\n",
    "\n",
    "\n",
    "class IsolationTree:\n",
    "    def __init__(self, height, height_limit):\n",
    "        self.height = height\n",
    "        self.height_limit = height_limit\n",
    "\n",
    "    def fit(self, X: np.ndarray, improved=False):\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, create an isolation tree. Set field\n",
    "        self.root to the root of that tree and return it.\n",
    "\n",
    "        If you are looking for an improved algorithm, check parameter \"improved\"\n",
    "        and switch to your new functionality else fall back on your original code.\n",
    "        \"\"\"\n",
    "        if improved:\n",
    "            self.improved_fit(X)\n",
    "        else:\n",
    "            if self.height >= self.height_limit or X.shape[0] <= 2:\n",
    "                self.root = LeafNode(X.shape[0], X)\n",
    "                return self.root\n",
    "\n",
    "            # Choose Random Split Attributes and Value\n",
    "            num_features = X.shape[1]\n",
    "            splitAtt = np.random.randint(0, num_features)\n",
    "            splitVal = np.random.uniform(min(X[:, splitAtt]), max(X[:, splitAtt]))\n",
    "\n",
    "            X_left = X[X[:, splitAtt] < splitVal]\n",
    "            X_right = X[X[:, splitAtt] >= splitVal]\n",
    "\n",
    "            left = IsolationTree(self.height + 1, self.height_limit)\n",
    "            right = IsolationTree(self.height + 1, self.height_limit)\n",
    "            left.fit(X_left)\n",
    "            right.fit(X_right)\n",
    "            self.root = DecisionNode(left.root, right.root, splitAtt, splitVal)\n",
    "            self.n_nodes = self.count_nodes(self.root)\n",
    "            return self.root\n",
    "\n",
    "    def improved_fit(self, X: np.ndarray):\n",
    "        if self.height >= self.height_limit or X.shape[0] <= 2:\n",
    "            self.root = LeafNode(X.shape[0], X)\n",
    "            return self.root\n",
    "\n",
    "        # Choose Best (The Most unbalanced) Random Split Attributes and Value\n",
    "        num_features = X.shape[1]\n",
    "        ratio_imp = 0.5 # Intialize the samples ratio after split as 0.5\n",
    "\n",
    "        for i in range(num_features):\n",
    "            splitAtt = i\n",
    "            for _ in range(10):\n",
    "                splitVal = np.random.uniform(min(X[:, splitAtt]), max(X[:, splitAtt]))\n",
    "                X_left = X[X[:, splitAtt] < splitVal]\n",
    "                X_right = X[X[:, splitAtt] >= splitVal]\n",
    "                ratio = min(X_left.shape[0] / (X_left.shape[0] + X_right.shape[0]),\n",
    "                            X_right.shape[0] / (X_left.shape[0] + X_right.shape[0]))\n",
    "                if ratio < ratio_imp:\n",
    "                    splitAtt_imp = splitAtt\n",
    "                    splitVal_imp = splitVal\n",
    "                    X_left_imp = X_left\n",
    "                    X_right_imp = X_right\n",
    "                    ratio_imp = ratio\n",
    "\n",
    "        left = IsolationTree(self.height + 1, self.height_limit)\n",
    "        right = IsolationTree(self.height + 1, self.height_limit)\n",
    "        left.fit(X_left_imp)\n",
    "        right.fit(X_right_imp)\n",
    "        self.root = DecisionNode(left.root, right.root, splitAtt_imp, splitVal_imp)\n",
    "        self.n_nodes = self.count_nodes(self.root)\n",
    "        return self.root\n",
    "\n",
    "    def count_nodes(self, root):\n",
    "        count = 0\n",
    "        stack = [root]\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            count += 1\n",
    "            if isinstance(node, DecisionNode):\n",
    "                stack.append(node.right)\n",
    "                stack.append(node.left)\n",
    "        return count\n",
    "\n",
    "\n",
    "class IsolationTreeEnsemble:\n",
    "    def __init__(self, sample_size, n_trees=10):\n",
    "        self.sample_size = sample_size\n",
    "        self.n_trees = n_trees\n",
    "\n",
    "    def fit(self, X: np.ndarray, improved=False):\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, create an ensemble of IsolationTree\n",
    "        objects and store them in a list: self.trees.  Convert DataFrames to\n",
    "        ndarray objects.\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        n_rows = X.shape[0]\n",
    "        height_limit = np.ceil(np.log2(self.sample_size))\n",
    "        for i in range(self.n_trees):\n",
    "            # data_index = np.random.choice(range(n_rows), size=self.sample_size, replace=False)\n",
    "            data_index = np.random.randint(0, n_rows, self.sample_size)\n",
    "            X_sub = X[data_index]\n",
    "            tree = IsolationTree(0, height_limit)\n",
    "            tree.fit(X_sub)\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "\n",
    "    def path_length(self, X:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, X, compute the average path length\n",
    "        for each observation in X.  Compute the path length for x_i using every\n",
    "        tree in self.trees then compute the average for each x_i.  Return an\n",
    "        ndarray of shape (len(X),1).\n",
    "        \"\"\"\n",
    "        paths = []\n",
    "        for row in X:\n",
    "            path = []\n",
    "            for tree in self.trees:\n",
    "                node = tree.root\n",
    "                length = 0\n",
    "                while isinstance(node, DecisionNode):\n",
    "                    if row[node.splitAtt] < node.splitVal:\n",
    "                        node = node.left\n",
    "                    else:\n",
    "                        node = node.right\n",
    "                    length += 1\n",
    "                leaf_size = node.size\n",
    "                pathLength = length + c(leaf_size)\n",
    "                path.append(pathLength)\n",
    "            paths.append(path)\n",
    "        paths = np.array(paths)\n",
    "        return np.mean(paths, axis=1)\n",
    "\n",
    "    def anomaly_score(self, X:pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D matrix of observations, X, compute the anomaly score\n",
    "        for each x_i observation, returning an ndarray of them.\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        avg_length = self.path_length(X)\n",
    "        scores = np.array([np.power(2, -l/c(self.sample_size))for l in avg_length])\n",
    "        return scores\n",
    "\n",
    "    def predict_from_anomaly_scores(self, scores:np.ndarray, threshold:float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given an array of scores and a score threshold, return an array of\n",
    "        the predictions: 1 for any score >= the threshold and 0 otherwise.\n",
    "        \"\"\"\n",
    "        return np.array([1 if s >= threshold else 0 for s in scores])\n",
    "\n",
    "    def predict(self, X:np.ndarray, threshold:float) -> np.ndarray:\n",
    "        \"A shorthand for calling anomaly_score() and predict_from_anomaly_scores().\"\n",
    "        scores = self.anomaly_score(X)\n",
    "        prediction = self.predict_from_anomaly_scores(scores, threshold)\n",
    "        return prediction\n",
    "\n",
    "\n",
    "def find_TPR_threshold(y, scores, desired_TPR):\n",
    "    \"\"\"\n",
    "    Start at score threshold 1.0 and work down until we hit desired TPR.\n",
    "    Step by 0.01 score increments. For each threshold, compute the TPR\n",
    "    and FPR to see if we've reached to the desired TPR. If so, return the\n",
    "    score threshold and FPR.\n",
    "    \"\"\"\n",
    "    TPR = 0\n",
    "    FPR = 0\n",
    "    threshold = 1\n",
    "    while TPR < desired_TPR:\n",
    "        threshold -= 0.01\n",
    "        prediction = [1 if s > threshold else 0 for s in scores]\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for p, label in zip(prediction, y):\n",
    "            if p == 1 and label == 1:\n",
    "                TP += 1\n",
    "            if p == 0 and label == 0:\n",
    "                TN += 1\n",
    "            if p == 1 and label == 0:\n",
    "                FP += 1\n",
    "            if p == 0 and label == 1:\n",
    "                FN += 1\n",
    "        # print(TP,TN,FP,FN)\n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        \n",
    "        if threshold < 0:\n",
    "            print(\"The model cannot reach the desired TPR\")\n",
    "            return\n",
    "\n",
    "    return threshold, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(df, n_noise):\n",
    "    for i in range(n_noise):\n",
    "        df[f'noise_{i}'] = np.random.normal(-2,2,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalies(X, y, sample_size=256, n_trees = 100, desired_TPR=None, percentile = None, normal_ymax=None, bins=20):\n",
    "    N = len(X)\n",
    "   \n",
    "\n",
    "    it = IsolationTreeEnsemble(sample_size=sample_size, n_trees=n_trees)\n",
    "\n",
    "    fit_start = time.time()\n",
    "    it.fit(X)\n",
    "    fit_stop = time.time()\n",
    "    fit_time = fit_stop - fit_start\n",
    "    print(f\"fit time {fit_time:3.2f}s\")\n",
    "\n",
    "    score_start = time.time()\n",
    "    scores = it.anomaly_score(X)\n",
    "    score_stop = time.time()\n",
    "    score_time = score_stop - score_start\n",
    "    print(f\"score time {score_time:3.2f}s\")\n",
    "    print('scores',)\n",
    "\n",
    "    if desired_TPR is not None:\n",
    "        print(\"y length\", len(y))\n",
    "        print(\"scores\", len(scores))\n",
    "\n",
    "        print(\"desired_TPR\", desired_TPR)\n",
    "        threshold, FPR = find_TPR_threshold(y, scores, desired_TPR)\n",
    "\n",
    "        print(f\"Computed {desired_TPR:.4f} TPR threshold {threshold:.4f} with FPR {FPR:.4f}\")\n",
    "    else:\n",
    "        threshold = np.percentile(scores, percentile)\n",
    "    y_pred = it.predict_from_anomaly_scores(scores, threshold=threshold)\n",
    "    # print(y_pred.unique())\n",
    "    # print(y.value_counts())\n",
    " \n",
    "    confusion = confusion_matrix(y, y_pred)\n",
    "       \n",
    "    # sns.heatmap(confusion, annot=True)\n",
    "    print(confusion)\n",
    "\n",
    "    TN, FP, FN, TP = confusion.flat\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    normal = scores[y==0]\n",
    "    anomalies = scores[y==1]\n",
    "    F1 = f1_score(y, y_pred)\n",
    "    PR = average_precision_score(y, scores)\n",
    "    print(f\"Proportion anomalies/normal = {len(anomalies)}/{len(normal)} = {(len(anomalies)/len(normal))*100:.1f}%\")\n",
    "    print(f\"F1 score {F1:.4f}, avg PR {PR:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "    counts0, binlocs0, _ = axes[0].hist(normal, color='#c7e9b4', bins=bins)\n",
    "    counts1, binlocs1, _ = axes[1].hist(anomalies, color='#fee090', bins=bins)\n",
    "    axes[1].set_xlabel(\"Anomaly score\")\n",
    "    axes[0].set_ylabel(\"Normal sample count\")\n",
    "    axes[1].set_ylabel(\"Anomalous sample count\")\n",
    "    axes[0].plot([threshold,threshold],[0,max(counts0)], '--', color='grey')\n",
    "    axes[1].plot([threshold,threshold],[0,max(counts1)], '--', color='grey')\n",
    "    text_xr = 0.97 * axes[0].get_xlim()[1]\n",
    "    axes[0].text(text_xr, .85 * max(counts0), f\"N {N}, {n_trees} trees\", horizontalalignment='right')\n",
    "    axes[0].text(text_xr, .75 * max(counts0), f\"F1 score {F1:.4f}, avg PR {PR:.4f}\", horizontalalignment='right')\n",
    "    axes[0].text(text_xr, .65 * max(counts0), f\"TPR {TPR:.4f}, FPR {FPR:.4f}\", horizontalalignment='right')\n",
    "    axes[0].text(threshold+.005, .20 * max(counts0), f\"score threshold {threshold:.3f}\")\n",
    "    axes[0].text(threshold+.005, .10 * max(counts0), f\"True anomaly rate {len(anomalies) / len(normal):.4f}\")\n",
    "    if normal_ymax is not None:\n",
    "        axes[0].set_ylim(0, normal_ymax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{'telecom'}-{n_trees}-{int(desired_TPR*100)}.svg\",\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalies_multiclass(X, y, sample_size=256, n_trees = 100, desired_TPR=None, percentile = None, normal_ymax=None, bins=20):\n",
    "    N = len(X)\n",
    "   \n",
    "\n",
    "    it = IsolationTreeEnsemble(sample_size=sample_size, n_trees=n_trees)\n",
    "\n",
    "    fit_start = time.time()\n",
    "    it.fit(X)\n",
    "    fit_stop = time.time()\n",
    "    fit_time = fit_stop - fit_start\n",
    "    print(f\"fit time {fit_time:3.2f}s\")\n",
    "\n",
    "    score_start = time.time()\n",
    "    scores = it.anomaly_score(X)\n",
    "    \n",
    "    score_stop = time.time()\n",
    "    score_time = score_stop - score_start\n",
    "    print(f\"score time {score_time:3.2f}s\")\n",
    "    print('scores',)\n",
    "\n",
    "    if desired_TPR is not None:\n",
    "        print(\"y length\", len(y))\n",
    "        print(\"scores\", len(scores))\n",
    "\n",
    "        print(\"desired_TPR\", desired_TPR)\n",
    "        threshold, FPR = find_TPR_threshold(y, scores, desired_TPR)\n",
    "\n",
    "        # print(f\"Computed {desired_TPR:.4f} TPR threshold {threshold:.4f} with FPR {FPR:.4f}\")\n",
    "    else:\n",
    "        threshold = np.percentile(scores, percentile)\n",
    "    y_pred = it.predict_from_anomaly_scores(scores, threshold=threshold)\n",
    "    # print(y_pred.unique())\n",
    "    # print(y.value_counts())\n",
    " \n",
    "    confusion = confusion_matrix(y, y_pred)\n",
    "       \n",
    "    # sns.heatmap(confusion, annot=True)\n",
    "    print(confusion)\n",
    "    print(confusion.size)\n",
    "    print(confusion.shape)\n",
    "    \n",
    "    #for i in confusion.size:\n",
    "    T_00, T_01, T_02, T_10, T_11 , T_12, T_20, T_21, T_22= confusion.flat\n",
    "    # TPR_0 = TP_0 / (TP_0 + FP_01+FP_02)\n",
    "    # TPR_1 = TP_1 / (TP_1 + FP_10+FP_12)\n",
    "    # TPR_2 = TP_2 / (TP_2 + FP_20+FP_21)\n",
    "   \n",
    "    # FPR_0 = FP / (FP + TN)\n",
    "    # FPR_0 = FP / (FP + TN)\n",
    "    # FPR_0 = FP / (FP + TN)\n",
    "    Pres_0 = T_00 / (T_00 + T_01 + T_02)\n",
    "    Pres_1 = T_11 / (T_11 + T_10 + T_12)\n",
    "    Pres_2 = T_22 / (T_22 + T_20 + T_21)\n",
    "    \n",
    "    Recall_0 = T_00 / (T_00 + T_10 + T_20)\n",
    "    Recall_1 = T_11 / (T_11 + T_01 + T_21)\n",
    "    Recall_2 = T_22 / (T_22 + T_02 + T_21)\n",
    "    \n",
    "    print(\"Pres_0\",Pres_0)  \n",
    "    print(\"Pres_1\",Pres_1)\n",
    "    print(\"Pres_2\",Pres_2)\n",
    "    normal_0 = scores[y==0]\n",
    "    anomalies_0 = scores[y!=0]\n",
    "    \n",
    "    normal_1 = scores[y==1]\n",
    "    anomalies_1 = scores[y!=1]\n",
    "    \n",
    "    normal_2 = scores[y==2]\n",
    "    anomalies_2 = scores[y!=2]\n",
    "    \n",
    "    # F1 = f1_score(y, y_pred)\n",
    "    F1_0 = 2 * (Pres_0 * Recall_0) / (Pres_0 + Recall_0)\n",
    "    F1_1 = 2 * (Pres_1 * Recall_1) / (Pres_1 + Recall_1)\n",
    "    F1_2 = 2 * (Pres_2 * Recall_2) / (Pres_2 + Recall_2)\n",
    "    \n",
    "    # PR = average_precision_score(y, scores)\n",
    "    # print(f\"Proportion anomalies/normal = {len(anomalies)}/{len(normal)} = {(len(anomalies)/len(normal))*100:.1f}%\")\n",
    "    # print(f\"F1 score {F1:.4f}, avg PR {PR:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "    counts0, binlocs0, _ = axes[0].hist(normal_0, color='#c7e9b4', bins=bins)\n",
    "    counts1, binlocs1, _ = axes[1].hist(anomalies_0, color='#fee090', bins=bins)\n",
    "    axes[1].set_xlabel(\"Anomaly score\")\n",
    "    axes[0].set_ylabel(\"Normal sample count\")\n",
    "    axes[1].set_ylabel(\"Anomalous sample count\")\n",
    "    # axes[0].plot([threshold,threshold],[0,max(counts0)], '--', color='grey')\n",
    "    # axes[1].plot([threshold,threshold],[0,max(counts1)], '--', color='grey')\n",
    "    text_xr = 0.97 * axes[0].get_xlim()[1]\n",
    "    axes[0].text(text_xr, .85 * max(counts0), f\"N {N}, {n_trees} trees\", horizontalalignment='right')\n",
    "    # axes[0].text(text_xr, .75 * max(counts0), f\"F1 score {F1_0:.4f}, avg PR {PR:.4f}\", horizontalalignment='right')\n",
    "    axes[0].text(text_xr, .65 * max(counts0), f\"TPR {Pres_0:.4f}, FPR {Recall_0:.4f}\", horizontalalignment='right')\n",
    "    axes[0].text(threshold+.005, .20 * max(counts0), f\"score threshold {threshold:.3f}\")\n",
    "    axes[0].text(threshold+.005, .10 * max(counts0), f\"True anomaly rate {len(anomalies_0) / len(normal_0):.4f}\")\n",
    "    if normal_ymax is not None:\n",
    "        axes[0].set_ylim(0, normal_ymax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{'telecom'}-{n_trees}-{int(desired_TPR*100)}.svg\",\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\experiments\\churn\\anomalydetection\\isolationforest.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\venv_pycaret_3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\venv_pycaret_3.8\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\venv_pycaret_3.8\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\experiments\\churn\\anomalydetection\\isolationforest.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scatter \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mscatter(X[:, \u001b[39m0\u001b[39;49m], X[:, \u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39my, s\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mk\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m handles, labels \u001b[39m=\u001b[39m scatter\u001b[39m.\u001b[39mlegend_elements()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\venv_pycaret_3.8\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\venv_pycaret_3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\venv_pycaret_3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "handles, labels = scatter.legend_elements()\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.title(\"Gaussian inliers with \\nuniformly distributed outliers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(max_samples=100, random_state=0)\n",
    "clf.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X,\n",
    "    response_method=\"predict\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "disp.ax_.set_title(\"Binary decision boundary \\nof IsolationForest\")\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desired_tpr 0.8\n",
      "fit time 0.07s\n",
      "score time 1.53s\n",
      "scores\n",
      "y length 300\n",
      "scores 300\n",
      "desired_TPR 0.8\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'threshold' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\experiments\\churn\\anomalydetection\\isolationforest.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# print(df.columns)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m X, y \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMarried\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNumber of Dependents\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mZip Code\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNumber of Referrals\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTenure in Months\u001b[39m\u001b[39m'\u001b[39m]], df[\u001b[39m'\u001b[39m\u001b[39mCustomer Status\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m plot_anomalies_multiclass(X, y, sample_size\u001b[39m=\u001b[39;49msample_size, n_trees\u001b[39m=\u001b[39;49mn_trees, desired_TPR\u001b[39m=\u001b[39;49mdesired_TPR, bins\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\ambreen.hanif\\Github\\slr_project\\experiments\\churn\\anomalydetection\\isolationforest.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# threshold, FPR = find_TPR_threshold(y, scores, desired_TPR)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# print(f\"Computed {desired_TPR:.4f} TPR threshold {threshold:.4f} with FPR {FPR:.4f}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     threshold \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpercentile(scores, percentile)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m y_pred \u001b[39m=\u001b[39m it\u001b[39m.\u001b[39mpredict_from_anomaly_scores(scores, threshold\u001b[39m=\u001b[39mthreshold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# print(y_pred.unique())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# print(y.value_counts())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ambreen.hanif/Github/slr_project/experiments/churn/anomalydetection/isolationforest.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m confusion \u001b[39m=\u001b[39m confusion_matrix(y, y_pred)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'threshold' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__': # dask seems to need this\n",
    "    # launch with \"python plot_anomalies.py http.csv attack 20000 256 100 99\"\n",
    "    # or, \"python plot_anomalies.py cancer.csv diagnosis all 5 1000 80\n",
    "    \n",
    "# for the random survival analysis data, try to use \"python plot_anomalies.py survival.csv status(risk score) all 5 1000 80\"\n",
    "# datafile = df_data_set\n",
    "# targetcol = score\n",
    "sample_size = 5\n",
    "n_trees = 1000\n",
    "desired_TPR = 80\n",
    "desired_TPR /= 100.0\n",
    "print(\"desired_tpr\",desired_TPR)\n",
    "val = 'all'\n",
    "\n",
    "# df = pd.read_csv(datafile)\n",
    "\n",
    "if val=='all':\n",
    "    N = len(telecom_data)\n",
    "    # print(N)\n",
    "# else:\n",
    "#     N = int(sys.argv[3])\n",
    "\n",
    "df = telecom_data.sample(300)  # grab random subset (too slow otherwise)\n",
    "# print(df.columns)\n",
    "X, y = df[['Gender','Age','Married','Number of Dependents','Zip Code','Number of Referrals', 'Tenure in Months']], df['Customer Status']\n",
    "plot_anomalies_multiclass(X, y, sample_size=sample_size, n_trees=n_trees, desired_TPR=desired_TPR, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pycaret_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
